import torch
from torchvision import transforms
from PIL import Image
import numpy as np
import matplotlib.pyplot as plt
import matplotlib.cm as cm
import argparse
import os
import json
import random
import re
from model import CSRNet

def main():
    """
    è¯¥è„šæœ¬ç”¨äºå¯¹ä¸€ä¸ªå›¾åƒåˆ—è¡¨è¿›è¡Œæ‰¹é‡å¤šå¸§è¾“å…¥çš„äººç¾¤è®¡æ•°æ¨ç†ï¼Œ
    å¹¶éšæœºç”Ÿæˆä¸€éƒ¨åˆ†æ ·æœ¬çš„å¯è§†åŒ–å¯¹æ¯”å›¾ã€‚
    """
    # --- 1. å®šä¹‰å‘½ä»¤è¡Œå‚æ•° ---
    parser = argparse.ArgumentParser(description='CSRNet Multi-Frame Batch Inference and Visualization')
    parser.add_argument('--model_path', type=str, required=True,
                        help='è®­ç»ƒå¥½çš„9é€šé“æ¨¡å‹æ£€æŸ¥ç‚¹è·¯å¾„ (.pth.tar)')
    parser.add_argument('--input_json', type=str, required=True,
                        help='åŒ…å«å›¾ç‰‡è·¯å¾„åˆ—è¡¨çš„JSONæ–‡ä»¶ (ä¾‹å¦‚: test.json æˆ– Val.json)')
    parser.add_argument('--output_dir', type=str, default='./batch_inference_results',
                        help='ä¿å­˜å¯è§†åŒ–å¯¹æ¯”å›¾çš„ç›®å½•')
    parser.add_argument('--num_visualizations', type=int, default=10,
                        help='è¦éšæœºç”Ÿæˆçš„å¯è§†åŒ–æ ·æœ¬æ•°é‡')
    args = parser.parse_args()

    # --- 2. ç¯å¢ƒè®¾ç½®å’Œç›®å½•åˆ›å»º ---
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    os.makedirs(args.output_dir, exist_ok=True)
    print(f"âœ… æ¨ç†è®¾å¤‡: {device}")
    print(f"âœ… å¯è§†åŒ–ç»“æœå°†ä¿å­˜è‡³: {args.output_dir}")

    transform = transforms.Compose([
        transforms.ToTensor(),
        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
    ])

    # --- 3. åŠ è½½æ¨¡å‹ ---
    print("\nğŸš€ æ­£åœ¨åŠ è½½æ¨¡å‹...")
    model = CSRNet().to(device)
    try:
        checkpoint = torch.load(args.model_path, map_location=device)
        model.load_state_dict(checkpoint['state_dict'])
        model.eval()
        print(f"âœ… æ¨¡å‹æˆåŠŸä» '{args.model_path}' åŠ è½½ã€‚")
    except Exception as e:
        print(f"âŒ åŠ è½½æ¨¡å‹å¤±è´¥: {e}")
        return

    # --- 4. åŠ è½½å›¾ç‰‡åˆ—è¡¨ ---
    try:
        with open(args.input_json, 'r') as f:
            image_paths = json.load(f)
        print(f"âœ… æˆåŠŸä» '{args.input_json}' åŠ è½½ {len(image_paths)} å¼ å›¾ç‰‡è·¯å¾„ã€‚")
    except Exception as e:
        print(f"âŒ åŠ è½½JSONæ–‡ä»¶å¤±è´¥: {e}")
        return

    # --- 5. æ‰¹é‡æ¨ç†å¾ªç¯ ---
    results = []
    print("\nğŸ§  å¼€å§‹æ‰¹é‡æ¨ç†...")
    for i, center_img_path in enumerate(image_paths):
        try:
            # è§£ææ–‡ä»¶å
            match = re.search(r'(\d+)_(\d+)\.jpg', os.path.basename(center_img_path))
            if not match:
                print(f"  - è­¦å‘Š: è·³è¿‡ä¸ç¬¦åˆæ ¼å¼çš„æ–‡ä»¶: {os.path.basename(center_img_path)}")
                continue
            
            seq_id, frame_num_str = match.groups()
            frame_num = int(frame_num_str)

            # æ„å»ºç›¸é‚»å¸§è·¯å¾„
            dir_name = os.path.dirname(center_img_path)
            prev_frame_path = os.path.join(dir_name, f"{seq_id}_{frame_num - 1:05d}.jpg")
            next_frame_path = os.path.join(dir_name, f"{seq_id}_{frame_num + 1:05d}.jpg")

            # å¤„ç†è¾¹ç•Œæƒ…å†µ
            prev_frame_path = prev_frame_path if os.path.exists(prev_frame_path) else center_img_path
            next_frame_path = next_frame_path if os.path.exists(next_frame_path) else center_img_path
            
            # åŠ è½½ä¸‰å¼ å›¾ç‰‡
            images = [Image.open(p).convert('RGB') for p in [prev_frame_path, center_img_path, next_frame_path]]
            
            # è½¬æ¢ä¸ºå¼ é‡å¹¶å †å 
            images_tensor = [transform(img) for img in images]
            stacked_tensor = torch.cat(images_tensor, dim=0).unsqueeze(0).to(device)
            
            # æ¨ç†
            with torch.no_grad():
                output = model(stacked_tensor)
            
            count = output.detach().cpu().sum().item()
            print(f"  [{i+1}/{len(image_paths)}] å›¾ç‰‡: {os.path.basename(center_img_path)}, é¢„æµ‹äººæ•°: {count:.2f}")

            results.append({
                'path': center_img_path,
                'count': count,
                'density_map': output.detach().cpu().squeeze().numpy()
            })
        except Exception as e:
            print(f"  - é”™è¯¯: å¤„ç†å›¾ç‰‡ {os.path.basename(center_img_path)} æ—¶å¤±è´¥: {e}")

    print("âœ… æ‰¹é‡æ¨ç†å®Œæˆï¼")

    # --- 6. éšæœºå¯è§†åŒ– ---
    if not results:
        print("\nâŒ æ²¡æœ‰æˆåŠŸçš„æ¨ç†ç»“æœï¼Œæ— æ³•ç”Ÿæˆå¯è§†åŒ–ã€‚")
        return

    num_to_visualize = min(args.num_visualizations, len(results))
    print(f"\nğŸ–¼ï¸  æ­£åœ¨éšæœºç”Ÿæˆ {num_to_visualize} å¼ å¯è§†åŒ–å¯¹æ¯”å›¾...")
    
    random_samples = random.sample(results, num_to_visualize)

    for sample in random_samples:
        img_raw = Image.open(sample['path']).convert('RGB')
        
        plt.figure(figsize=(20, 10))
        
        # åŸå›¾
        plt.subplot(1, 2, 1)
        plt.imshow(img_raw)
        plt.title('Original Image')
        plt.axis('off')
        
        # é¢„æµ‹å¯†åº¦å›¾
        plt.subplot(1, 2, 2)
        plt.imshow(sample['density_map'], cmap=cm.jet)
        plt.title(f"Predicted Density Map\nCount: {sample['count']:.2f}")
        plt.axis('off')
        
        # ä¿å­˜å›¾åƒ
        output_filename = os.path.join(args.output_dir, f"vis_{os.path.basename(sample['path'])}")
        plt.savefig(output_filename, bbox_inches='tight')
        plt.close() # é‡Šæ”¾å†…å­˜
        print(f"  - å·²ä¿å­˜å¯¹æ¯”å›¾: {os.path.basename(output_filename)}")

    print("ğŸ‰ æ‰€æœ‰ä»»åŠ¡å®Œæˆï¼")

if __name__ == '__main__':
    main()
